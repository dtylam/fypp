%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Seventh Chapter **********************************
%*******************************************************************************
\chapter{Evaluation}

Coming to the end of the project, evaluation was needed to measure and draw conclusions
on its effectiveness. The project was evaluated in two ways: requirement-based testing and user evaluation.

\section{Requirement-based Testing}

One way to determine product quality is to evaluate the extent to which each stated requirement
has been fulfilled \citep{bach1999risk}. Since the requirements for this project addressed directly
several of the problems found in literature and interviews with stakeholders, a high-quality product
that satisfies these requirements would make the project more of a success.

This can be done with black box testing, with test cases that are traceable to one or more of
the requirements as stated in Chapter 4.2.

The full list of requirement-based test cases run are listed in Appendix E.
Overall, the results were positive.
Out of the 19 requirement-based test cases developed, only 4 were not completely passing.
They were all due to time limitations on implementation work.
Remedial actions were carried out for the failed cases:

\begin{table}[!ht]
	% \caption{Remedial actions for failed requirements}
	% \label{table:failed_tests}
	\begin{tabularx}{\textwidth}{|c|c|X|c|}
		\hline
		Test                                  & Req                                                                                                                                          & Requirement Statement                                                 & Status                 \\
		\hline
		2                                     & FR2                                                                                                                                          & \textbf{Teachers would be able to create and edit learning resources} & \cellcolor{pink}FAILED \\
		\hline
		3                                     & FR3                                                                                                                                          & \textbf{Teachers would be able to create and edit assessments}        & \cellcolor{pink}FAILED \\
		\hline
		12                                                                & FR12                    & \textbf{The system would be able to generate certificates on
		the blockchain when a course has been completed}                  & \cellcolor{pink}FAILED                                                                                                                                                                                    \\
		\hline
		\multicolumn{2}{|c|}{Explanations}     & \multicolumn{2}{X|}{Due to time limitation, features for editing existing courses and assessments, and features related to certificates have not been built.}                                                                                                                        \\
		\hline
		\multicolumn{2}{|c|}{Remedial Action} & \multicolumn{2}{X|}{During demonstrations, participants were told these features are possible and would be made available in future work.}                                                                                                  \\
		\hline
	\end{tabularx}
\end{table}
\clearpage
\begin{table}[!ht]	
	\begin{tabularx}{\textwidth}{|c|c|X|c|}
		\hline
		15 & NR1 & \textbf{The client applications would have the same functionalities
		across devices and a responsive interface} & \cellcolor{pink}FAILED \\
		\hline
		\multicolumn{2}{|c|}{Explanations} & \multicolumn{2}{X|}{
			A majority of pages have been optimised for smaller screens \underline{but not all}. 
			The applications work on all JavaScript enabled browsers across devices.
		   }      \\
		\hline
		\multicolumn{2}{|c|}{Remedial Action} & \multicolumn{2}{X|}{During demonstrations, the responsive design of webpages was showcased only on working pages.}                                                                                                  \\
		\hline
	\end{tabularx}	
\end{table}

A limitation of these tests was that they were performed by the same person as the developer,
and could lead to biased results.
For example, no test cases have been developed for non-functional requirements NR4 and NR5,
because they described criteria that cannot be objectively assessed by the developer.

\section{User Evaluation}

The aims of the project aimed to deliver benefits to students and teachers.
It is therefore important to evaluate what these real-world stakeholders think about the project deliverables.

\subsection{Methodology}

Similar to the requirements gathering study in Chapter 4, a qualitative study was conducted
with semi-structured, face-to-face interviews.

Another ethics submission was completed on BREO and approval was granted on 14th March.
See Supporting Materials/Ethics/Evaluation/ for the approval letter, 
participant information sheet, consent form, and example questions documents.

The participants were gathered through directly emailing existing contacts (convenience sampling).
The criteria were the same as the requirements study: higher education teaching staff
with 10+ years of experience, and students with academic liaison experience.

A total of four interviews were conducted in March 2018.
Three of the participants (A, C, E) are return participants from the requirements gathering interviews in Chapter 4.
See table \ref{table:participants-eval} for a more detailed description of these participants.

\begin{table}[!h]
	\caption{Participants in user evaluation interviews}
	\centering
	\label{table:participants-eval}
	\begin{tabularx}{\textwidth}{>{\bfseries}lX}
		Participant & Characterisation                                                                    \\
		\toprule
		Educator A  & lecturer in higher education for over 20 years, and an experienced higher education
		administrator                                                                                     \\\midrule
		Educator F  & lecturer in higher education for over 10 years                                      \\\midrule
		Student C   & university course representative for 3 years                    \\\midrule
		Student E   & university course representative for 2 years, peer-assisted learning leader
		for 1 year                                                                                        \\\bottomrule
	\end{tabularx}
\end{table}

\subsection{Interview Results and Analysis}

To better draw conclusions on the aims and objectives of this project, 
a Likert-type scale was used for the first eight questions. 
They may look like structured questions, but participants were asked to give 
"How and Why?" follow-up responses after selecting an option on the scale. 

The inclusion of the scale was to encourage participants to express an agree/ disagree opinion 
about the guiding statements, not for quantitative analysis. 
See Table \ref{table:structuredresp_eval} for 
the response values for these first eight questions,
where 1 is for Strongly disagree, 2 for Disagree, 3 for Neither agree nor disagree, 
4 for Agree, and 5 for Strongly agree.

\begin{table}[!ht]
	\caption{Responses to structured questions in user evaluation}
	\centering
	\label{table:structuredresp_eval}
	\begin{tabularx}{\textwidth}{|c|X|c|c|c|c|}
		\hline
		   &                                                                                            & \multicolumn{4}{c|}{Participants}                                                                                \\
		\hline
		   & Statement                                                                                  & A                                 & F                      & C                        & E                        \\
		\hline
		Q1 & The features of the system communicate assessment expectations well                        & \cellcolor{Dandelion}3            & \cellcolor{green}5     & \cellcolor{SpringGreen}4 & \cellcolor{SpringGreen}4 \\
		\hline
		Q2 & The features of the system improve transparency in assessment procedures                   & \cellcolor{Dandelion}3            & \cellcolor{green}5     & \cellcolor{green}5       & \cellcolor{green}5       \\
		\hline
		Q3 & The features of the system make curriculum personalisation convenient                      & \cellcolor{green}5                & \cellcolor{green}5     & \cellcolor{green}5       & \cellcolor{SpringGreen}4 \\
		\hline
		Q4 & The system provides good (administrative/ pastoral) support for curriculum personalisation & \cellcolor{green}5                & \cellcolor{green}5     & \cellcolor{SpringGreen}4 & \cellcolor{Dandelion}3   \\
		\hline
		Q5 & The system can reduce tension and disagreements between educators and students             & \cellcolor{SpringGreen}4          & \cellcolor{Dandelion}3 & \cellcolor{Dandelion}3   & \cellcolor{SpringGreen}4 \\
		\hline
		Q6 & The system makes educational history more transparent and trustworthy                      & \cellcolor{green}5                & \cellcolor{green}5     & \cellcolor{Dandelion}3   & \cellcolor{green}5       \\
		\hline
		Q7 & The access control features of the system preserve student privacy                         & \cellcolor{SpringGreen}4          & \cellcolor{green}5     & \cellcolor{green}5       & \cellcolor{green}5       \\
		\hline
		Q8 & The system increases trust in online education providers and credentials                   & \cellcolor{SpringGreen}4          & \cellcolor{green}5     & \cellcolor{SpringGreen}4 & \cellcolor{SpringGreen}4 \\
		\hline
	\end{tabularx}
\end{table}

Overall, the participants have rated the demonstrator system positively.
None of the participants have disagreed with the above statements about the demonstrator,
which was an encouraging sign.
The lowest rated statement was Q5, where most participants have stated that 
they thought the system will help resolve conflicts and disagreements between 
teachers and students, but they could not say with great confidence 
that it could reduce the number of conflicts.

Moving on, the rest of the raw data ("How and Why" responses and open-ended questions) 
from interviews (transcripts) were analysed and grouped using thematic analysis techniques into
observational statements (OS) and functionality suggestions (FS).

These statements and suggestions were sorted into three affinity groups:
1. assessments, 2. curriculum personalisation, and 3. privacy, security and trust.
For the relevant transcript snippets for each evaluation question asked,
please go to Appendix D.
Here is a high-level discussion on the results:

\subsubsection{On Assessments}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		    & Statement or Suggestion                                                                                                              & Participant \\
		\hline
		OS1 & \textbf{The system schema encourages communication of expectations, but the quality of communication depends on the course creators} & A           \\
		\hline
		% \multicolumn{3}{|X|}{} \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		OS2 & \textbf{The "assessment contract" is a good reminder for students before submission} & E \\
		\hline
		% \multicolumn{3}{|X|}{} \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		OS3 & \textbf{The "assessment contract" could become a source of stress} & E \\
		\hline
		% \multicolumn{3}{|X|}{} \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		OS4 & \textbf{Assessment feedback is enhanced by the transparency of marking criteria and grade split down} & A, F, E \\
		\hline
		% \multicolumn{3}{|X|}{} \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		OS5 & \textbf{The system help resolve tension and disagreements, not necessarily reduce them} & A, F, E \\
		\hline
		% \multicolumn{3}{|X|}{} \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		FS1 & \textbf{Links or further explanations for knowledge required} & F \\
		\hline
		% \multicolumn{3}{|X|}{} \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		FS2 & \textbf{Assessment appeals and special circumstances requests should be logged on the blockchain} & C \\
		\hline
		% \multicolumn{3}{|X|}{} \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		FS3 & \textbf{Teachers should be able to override calculated grades} & C \\
		\hline
		\multicolumn{3}{|X|}{
			A grade override functionality that require a written reason could provide
			flexibility to teachers but still maintain transparency to students.
		}                                                                        \\
		\hline
	\end{tabularx}
\end{table}

The participant reactions to the assessment features have been largely positive, 
with comments such as "that is more than what we offer to students right now" from 
Educator F.
The "assessment contract" feature and the provision of marking criteria were praised (OS2, OS4).

Participants have suggested several interesting features.
Teachers disliked the lack of control over the final grade output, and would like 
the ability to override the grade (FS3).
Notably, assessment appeals (FS2) is an important area that a blockchain-based system 
could be great at facilitating, but unfortunately did not come up in the previous 
requirements gathering study.

\subsubsection{On Curriculum Personalisation}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		OS6 & \textbf{The curriculum personalisation user interface was informative and easy to use} & A, F, C, E \\
		\hline
		% \multicolumn{3}{|X|}{} \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		OS7 & \textbf{The direct messages with tutors and advisors is a great channel for administrative and pastoral support} & A, F, C, E \\
		\hline
		% \multicolumn{3}{|X|}{} \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		FS4 & \textbf{The learner-staff chat records could be kept on the blockchain} & A \\
		\hline
		% \multicolumn{3}{|X|}{} \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		FS5 & \textbf{The approval process reduces the final say of the student.} & E \\
		\hline
		\multicolumn{3}{|X|}{
			The approval of a curriculum is done by the teacher, which could produce a 
			situation where a teacher refuses to approve a student's curriculum unless they change their modules. 
			It is suggested that students should have the final decision on course 
			selection, which is how module selection is more popularly done.
		} \\
		\hline
	\end{tabularx}
\end{table}

Curriculum personalisation features were also highly praised,
with all participants noting that they liked the "My Curriculum" page in the 
learner application. The availability of support in the form of the direct message 
chat box was also unanimously praised (OS7).

An important suggestion was raised by Student E, that current systems give 
students the final say over module choices, whereas the demonstrator system 
gave teachers the final say (FS5). To correct this, a future iteration of 
the design could separate the selection of modules (done by students), 
and the editing of programme specifications (done by teacher) into two transactions.

% Educator A raised the issue of "who issues the final degree award?",

\subsubsection{Privacy, Security and Trust}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		OS8 & \textbf{Access Controls previews are useful} & A, F, C \\
		\hline
		\multicolumn{3}{|X|}{
			This feature was highly praised for giving control directly in the hands of students.
		}                                                            \\
		\hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		OS9 & \textbf{Secure storage of detailed records prevent future education history disputes} & A \\
		\hline
		% \multicolumn{3}{|X|}{
		% } \\
		% \hline
	\end{tabularx}
\end{table}

\begin{table}[!ht]
	\begin{tabularx}{\textwidth}{|c|X|c|}
		\hline
		FS6 & \textbf{A crowdsourced reputation building model for course modules} & A \\
		\hline
		\multicolumn{3}{|X|}{
			A module rating system for students and other academic staff could build trust
			in the quality of content and assessments.
		}                                                                              \\
		\hline
	\end{tabularx}
\end{table}

No red flags were raised by the participants about the access control rules the system used.
The access control UI in the learner application was received very positively.
The provenance and security of blockchain records would also add value in resolving disputes (OS5, OS9).

All of the participants thought that the added degree of transparency and provenance 
could increase trust in online education providers and credentials (Q8).
This is very encouraging. A crowd-sourced/ community-policing ratings feature was 
suggested (FS6) to further allow trust and reputation building on the system.

Throughout the demonstrations held, a lot of time and effort has to be put in describing
how the blockchain was set up, and explaining the benefits of running assessments, 
and negotiating personalised curricula with Smart Contracts.
This showed that the user interfaces and instructions were not effective enough in relaying the
benefits of these features, and that public awareness of blockchain benefits was still quite primitive.

\section{Conclusion}

The demonstrator system has been a moderate success. 15 out of 19 of the requirement-based test cases have been passed and
user evaluation feedback has been positive overall.
All of the participants interviewed said they would enrol into a platform like this in the future 
(Appendix D.2.Q10), praising its transparency, security and user experience.
Participants have also confirmed that the added provenance behind education processes and credentials 
could increase their trustworthiness.

Going back to the objectives of the design of the demonstrator system,
Table \ref{table:eval_conclusion} summarises how well these objectives have been achieved.

\begin{table}[!ht]
	\caption{Conclusions drawn from user evaluation}
	\label{table:eval_conclusion}
	\begin{tabularx}{\textwidth}{|>{\bfseries}l|X|}
		\hline
		Objective & Conclusion from participant responses
		\\\hline
		Increase transparency in assessments & The system can achieve this, assuming that the human inputs are of high quality.
		\\\hline
		Facilitate curriculum personalisation & The system has been well designed to do this.
		\\\hline	
		Increase security and privacy & The system has more access control features, more security, provenance, and redundancy built-in than regular systems.
		\\\hline
	\end{tabularx}
\end{table}

% Teacher participants expressed confusion around the targeted market of the application, 