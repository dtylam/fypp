%!TEX root = ../thesis.tex
%*******************************************************************************
%****************************** Seventh Chapter **********************************
%*******************************************************************************
\chapter{Evaluation}

Coming to the end of the project, evaluation is needed to measure and draw conclusions
on its effectiveness. The project will be evaluated in two ways:
software testing and user evaluation.

\section{Software Testing}

White box testing. Why?

A requirements testing tracibility matrix in the format of [TODO] is used.

The test results are overall positive.

It may be biased because it is performed by me.

\section{User Evaluation}

User evaluation is important because...

\subsection{Methodology}
[TODO]

Method: qualitative

Instrument: Why interviews? Likert Scale and semi-structured.

Sample: Who are they? Why? Convenience Sampling. Limitation: all CS department.

An ethics submission was completed on BREO and approval granted on 14th March.
See Appendix (TODO) for the approved participant information sheet, consent form and example questions.

A total of four interviews were conducted in March 2018:
two with teaching staff and two with student representatives.
Three of the participants (A, C, E) are return participants from the requirements gathering interviews in Chapter 4.
See table \ref{table:participants-eval} for a more detailed description of these participants.

\begin{table}[!h]
	\caption{Participants in user evaluation interviews}
	\centering
	\label{table:participants-eval}
	\begin{tabularx}{\textwidth}{>{\bfseries}lX}
		Participant & Characterisation                                                                    \\
		\toprule
		Educator A  & lecturer in higher education for over 20 years, and an experienced higher education
		administrator                                                                                     \\\midrule
		Educator F  & lecturer in higher education for over 10 years                                      \\\midrule
		Student C   & a university course representative for 3 years, which involves collecting and
		communicating student feedback and attending staff-student liaison meetings                       \\\midrule
		Student E   & a university course representative for 2 years and a peer assisted learning leader
		for 1 year                                                                                        \\\bottomrule
	\end{tabularx}
\end{table}

\subsection{Interview Results and Analysis}

To better draw conclusions on the aims and objectives of this project, a Likert-type scale is used
for the first eight structured questions. This is to encourage participants to express an opinion about the guiding statements,
not for quantitative analysis. See Table \ref{table:structuredresp_eval} for the response values for these first eight questions:

\begin{table}[!ht]
	\caption{Responses for structured questions in user evaluation}
	\centering
	\label{table:structuredresp_eval}
    \begin{tabularx}{\textwidth}{|c|X|c|c|c|c|}
        \hline
        & & \multicolumn{4}{c}{Participants}\\
		\hline
		   & Statement                                                                                  & A                        & F                      & C                        & E                        \\
		\hline
		Q1 & The features of the system communicate assessment expectations very well                   & \cellcolor{Dandelion}3   & \cellcolor{green}5     & \cellcolor{SpringGreen}4 & \cellcolor{SpringGreen}4 \\
		\hline
		Q2 & The features of the system improve transparency in assessment procedures                   & \cellcolor{Dandelion}3   & \cellcolor{green}5     & \cellcolor{green}5       & \cellcolor{green}5       \\
		\hline
		Q3 & The features of the system make curriculum personalisation convenient                      & \cellcolor{green}5       & \cellcolor{green}5     & \cellcolor{green}5       & \cellcolor{SpringGreen}4 \\
		\hline
		Q4 & The system provides good (administrative/ pastoral) support for curriculum personalisation & \cellcolor{green}5       & \cellcolor{green}5     & \cellcolor{green}4       & \cellcolor{Dandelion}3   \\
		\hline
		Q5 & The system can reduce tension and disagreements between educators and students             & \cellcolor{SpringGreen}4 & \cellcolor{Dandelion}3 & \cellcolor{Dandelion}3   & \cellcolor{SpringGreen}4 \\
		\hline
		Q6 & The system makes educational history more transparent and trustworthy                      & \cellcolor{green}5       & \cellcolor{green}5     & \cellcolor{Dandelion}3   & \cellcolor{green}5       \\
		\hline
		Q7 & The access control features of the system preserve student privacy                         & \cellcolor{SpringGreen}4 & \cellcolor{green}5     & \cellcolor{green}5       & \cellcolor{green}5       \\
		\hline
		Q8 & The system increases trust in online education providers and credentials                   & \cellcolor{SpringGreen}4 & \cellcolor{green}5     & \cellcolor{SpringGreen}4 & \cellcolor{SpringGreen}4 \\
		\hline
	\end{tabularx}
\end{table}

Overall, the participants have rated the demonstrator system positively.

The rest of the raw data from interviews (transcripts) were contextually analysed and grouped into observational statements (OS),

Any specifics regarding course, staff and event details have been anonymised.

Educator A raised the issue of "Who issues the award?"

\section{Conclusion}